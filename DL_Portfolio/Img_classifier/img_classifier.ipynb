{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hwT_nzD0waDR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "sns.set(style='white', context='notebook', palette='deep')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.read_csv(\"/content/X_train.csv\")\n",
        "Y_train = pd.read_csv(\"/content/y_train.csv\")\n",
        "def train_predict(X_train, Y_train,*X_test):\n",
        "  # print(X_train.isnull().any().describe())\n",
        "  # Normalize the data\n",
        "  X_train = X_train / 255.0\n",
        "  \n",
        "  # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
        "  X_train = X_train.values.reshape(-1,28,28,1)\n",
        "  \n",
        "\n",
        "  Y_train=Y_train.apply(LabelEncoder().fit_transform)\n",
        "  Y_train = to_categorical(Y_train, 94)\n",
        "  \n",
        "  # X_test = X_test / 255.0\n",
        "  # X_test = X_test.values.reshape(-1,28,28,1)\n",
        "\n",
        "  random_seed = 2\n",
        "  # Split the train and the validation set for the fitting\n",
        "  X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)\n",
        "  \n",
        "  # g = plt.imshow(X_train[0][:,:,0])\n",
        "  # print(g)\n",
        "  \n",
        "  # Set the CNN model \n",
        "  # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense ->Dropout ->Dense-> Dropout -> Out\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation = \"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(500, activation = \"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(94, activation = \"softmax\"))\n",
        "\n",
        "  # Define the optimizer\n",
        "  optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "  # Compile the model\n",
        "  model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  \n",
        "  # Set a learning rate annealer\n",
        "  learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "  epochs = 30 \n",
        "  batch_size = 90\n",
        "\n",
        "  # With data augmentation to prevent overfitting \n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "  datagen.fit(X_train)\n",
        "  history = model.fit(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
        "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
        "                              , callbacks=[learning_rate_reduction])\n",
        " \n",
        "  Y_pred = model.predict(X_val)\n",
        "  Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        " \n",
        "  print(\"PREDICTED CLASSES FOR VALIDATION DATASET: \", Y_pred_classes)\n",
        "\n",
        "  # predict results\n",
        "  # results = model.predict(X_test)\n",
        "\n",
        "  # # select the indix with the maximum probability\n",
        "  # results = np.argmax(results,axis = 1)\n",
        "\n",
        "  # results = pd.Series(results,name=\"Label\")\n",
        "  # print(results)\n",
        "  model.save('img_classifier.h5')\n",
        "  \n",
        "  return model.summary()\n",
        "\n",
        "\n",
        "train_predict(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdstYzbrwcqr",
        "outputId": "aa26ee85-6732-40c2-f63c-5d9d8d171a32"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "200/200 - 7s - loss: 3.6669 - accuracy: 0.1188 - val_loss: 1.7076 - val_accuracy: 0.5180 - lr: 0.0010 - 7s/epoch - 34ms/step\n",
            "Epoch 2/30\n",
            "200/200 - 6s - loss: 2.0220 - accuracy: 0.4213 - val_loss: 0.8477 - val_accuracy: 0.7355 - lr: 0.0010 - 6s/epoch - 28ms/step\n",
            "Epoch 3/30\n",
            "200/200 - 6s - loss: 1.3932 - accuracy: 0.5770 - val_loss: 0.6551 - val_accuracy: 0.7785 - lr: 0.0010 - 6s/epoch - 29ms/step\n",
            "Epoch 4/30\n",
            "200/200 - 6s - loss: 1.0885 - accuracy: 0.6606 - val_loss: 0.5140 - val_accuracy: 0.8330 - lr: 0.0010 - 6s/epoch - 28ms/step\n",
            "Epoch 5/30\n",
            "200/200 - 6s - loss: 0.9410 - accuracy: 0.7029 - val_loss: 0.4657 - val_accuracy: 0.8475 - lr: 0.0010 - 6s/epoch - 29ms/step\n",
            "Epoch 6/30\n",
            "200/200 - 6s - loss: 0.8068 - accuracy: 0.7474 - val_loss: 0.4498 - val_accuracy: 0.8465 - lr: 0.0010 - 6s/epoch - 29ms/step\n",
            "Epoch 7/30\n",
            "200/200 - 6s - loss: 0.7327 - accuracy: 0.7698 - val_loss: 0.4418 - val_accuracy: 0.8420 - lr: 0.0010 - 6s/epoch - 29ms/step\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "200/200 - 6s - loss: 0.6841 - accuracy: 0.7819 - val_loss: 0.4333 - val_accuracy: 0.8435 - lr: 0.0010 - 6s/epoch - 29ms/step\n",
            "Epoch 9/30\n",
            "200/200 - 6s - loss: 0.5881 - accuracy: 0.8140 - val_loss: 0.3842 - val_accuracy: 0.8700 - lr: 5.0000e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 10/30\n",
            "200/200 - 6s - loss: 0.5568 - accuracy: 0.8238 - val_loss: 0.3561 - val_accuracy: 0.8865 - lr: 5.0000e-04 - 6s/epoch - 28ms/step\n",
            "Epoch 11/30\n",
            "200/200 - 6s - loss: 0.5396 - accuracy: 0.8289 - val_loss: 0.3663 - val_accuracy: 0.8740 - lr: 5.0000e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 12/30\n",
            "200/200 - 6s - loss: 0.5185 - accuracy: 0.8336 - val_loss: 0.3448 - val_accuracy: 0.8870 - lr: 5.0000e-04 - 6s/epoch - 28ms/step\n",
            "Epoch 13/30\n",
            "200/200 - 6s - loss: 0.5165 - accuracy: 0.8406 - val_loss: 0.3663 - val_accuracy: 0.8645 - lr: 5.0000e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 14/30\n",
            "200/200 - 6s - loss: 0.4921 - accuracy: 0.8471 - val_loss: 0.3682 - val_accuracy: 0.8685 - lr: 5.0000e-04 - 6s/epoch - 28ms/step\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "200/200 - 6s - loss: 0.4943 - accuracy: 0.8451 - val_loss: 0.3751 - val_accuracy: 0.8680 - lr: 5.0000e-04 - 6s/epoch - 28ms/step\n",
            "Epoch 16/30\n",
            "200/200 - 6s - loss: 0.4596 - accuracy: 0.8543 - val_loss: 0.3507 - val_accuracy: 0.8825 - lr: 2.5000e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 17/30\n",
            "200/200 - 6s - loss: 0.4451 - accuracy: 0.8591 - val_loss: 0.3227 - val_accuracy: 0.8940 - lr: 2.5000e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 18/30\n",
            "200/200 - 6s - loss: 0.4421 - accuracy: 0.8649 - val_loss: 0.3391 - val_accuracy: 0.8810 - lr: 2.5000e-04 - 6s/epoch - 28ms/step\n",
            "Epoch 19/30\n",
            "200/200 - 6s - loss: 0.4343 - accuracy: 0.8668 - val_loss: 0.3648 - val_accuracy: 0.8725 - lr: 2.5000e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "200/200 - 6s - loss: 0.4368 - accuracy: 0.8662 - val_loss: 0.3136 - val_accuracy: 0.8880 - lr: 2.5000e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 21/30\n",
            "200/200 - 6s - loss: 0.4191 - accuracy: 0.8704 - val_loss: 0.3489 - val_accuracy: 0.8755 - lr: 1.2500e-04 - 6s/epoch - 29ms/step\n",
            "Epoch 22/30\n",
            "200/200 - 6s - loss: 0.4114 - accuracy: 0.8736 - val_loss: 0.3362 - val_accuracy: 0.8815 - lr: 1.2500e-04 - 6s/epoch - 28ms/step\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "200/200 - 6s - loss: 0.4073 - accuracy: 0.8745 - val_loss: 0.3132 - val_accuracy: 0.8895 - lr: 1.2500e-04 - 6s/epoch - 30ms/step\n",
            "Epoch 24/30\n",
            "200/200 - 6s - loss: 0.3966 - accuracy: 0.8795 - val_loss: 0.3283 - val_accuracy: 0.8855 - lr: 6.2500e-05 - 6s/epoch - 29ms/step\n",
            "Epoch 25/30\n",
            "200/200 - 6s - loss: 0.3958 - accuracy: 0.8793 - val_loss: 0.3434 - val_accuracy: 0.8790 - lr: 6.2500e-05 - 6s/epoch - 29ms/step\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "200/200 - 6s - loss: 0.3961 - accuracy: 0.8771 - val_loss: 0.3287 - val_accuracy: 0.8855 - lr: 6.2500e-05 - 6s/epoch - 29ms/step\n",
            "Epoch 27/30\n",
            "200/200 - 6s - loss: 0.3906 - accuracy: 0.8782 - val_loss: 0.3216 - val_accuracy: 0.8880 - lr: 3.1250e-05 - 6s/epoch - 28ms/step\n",
            "Epoch 28/30\n",
            "200/200 - 6s - loss: 0.3840 - accuracy: 0.8809 - val_loss: 0.3413 - val_accuracy: 0.8795 - lr: 3.1250e-05 - 6s/epoch - 29ms/step\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "200/200 - 6s - loss: 0.3938 - accuracy: 0.8808 - val_loss: 0.3297 - val_accuracy: 0.8860 - lr: 3.1250e-05 - 6s/epoch - 28ms/step\n",
            "Epoch 30/30\n",
            "200/200 - 6s - loss: 0.3963 - accuracy: 0.8784 - val_loss: 0.3269 - val_accuracy: 0.8865 - lr: 1.5625e-05 - 6s/epoch - 28ms/step\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "PREDICTED CLASSES FOR VALIDATION DATASET:  [46 62  6 ... 63 77 82]\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 28, 28, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 256)               803072    \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 500)               128500    \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 500)               0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 94)                47094     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,060,554\n",
            "Trainable params: 1,060,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}